{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPuhtBTJ2VHmahta7HG78M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeremstar/ca-va-predire-l-inflation-severe/blob/main/Sp%C3%A9cifications%2026/04\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utd-QlOm8Vob"
      },
      "outputs": [],
      "source": [
        "# pip install openpyxl\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OECD = pd.read_excel('données/OECD - short term economic indicators.xlsx')\n",
        "\n",
        "IMF = pd.read_excel('données/IMF - monetary policy.xlsx')\n",
        "\n",
        "agregated_data=pd.ExcelFile('données/FRBNY-SCE-Data.xlsx')\n",
        "agregated_anticipation= df1=pd.read_excel(agregated_data, 'Inflation expectations')\n",
        "\n",
        "agrant = agregated_anticipation[['Unnamed: 1','Unnamed: 2']].drop([0,1,2]).reset_index().rename(columns={'index':'date','Unnamed: 1':'short exp','Unnamed: 2':'mid exp'})\n",
        "\n",
        "Enq13 = pd.read_excel('https://www.newyorkfed.org/medialibrary/interactives/sce/sce/downloads/data/frbny-sce-public-microdata-complete-13-16.xlsx')\n",
        "\n",
        "Enq17 = pd.read_excel('https://www.newyorkfed.org/medialibrary/interactives/sce/sce/downloads/data/frbny-sce-public-microdata-complete-17-19.xlsx')\n",
        "\n",
        "Latest=pd.ExcelFile('https://www.newyorkfed.org/medialibrary/Interactives/sce/sce/downloads/data/frbny-sce-public-microdata-latest.xlsx')\n",
        "\n",
        "Enq20=pd.read_excel(Latest, 'Data')\n",
        "\n",
        "# ça c'était pour le 'W' mais comme j'avais que le PIB j'ai laissé tombé pour cette fois\n",
        "#pib = pd.read_excel(r'C:\\Users\\3e3gr\\OneDrive\\Documents\\ENSAE\\2A-S2\\StatApp\\PIBUS1.xlsx').drop(list(range(0,35))).rename(columns = {'Produit intérieur brut des États-Unis 1980-2021' : 'date','Unnamed: 1':'PIB'}) #en milliard de $ courant\n",
        "\n",
        "#pib.set_index('date',inplace=True)\n",
        "\n",
        "# u = pd.read_excel(r'C:\\Users\\3e3gr\\OneDrive\\Documents\\ENSAE\\2A-S2\\StatApp\\chomageUS.xlsx')\n"
      ],
      "metadata": {
        "id": "2UQVtsIV8iS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Il faut faire 2-3 manips pour rendre les bases utilisables\n",
        "new_columns = Enq13.iloc[0]\n",
        "Enq13.columns = new_columns\n",
        "Enq13 = Enq13.drop(0)\n",
        "\n",
        "new_columns = Enq17.iloc[0]\n",
        "Enq17.columns = new_columns\n",
        "Enq17 = Enq17.drop(0)\n",
        "new_columns = Enq20.iloc[0]\n",
        "Enq20.columns = new_columns\n",
        "Enq20 = Enq20.drop(0)\n",
        "Enq17['date'] = pd.to_datetime(Enq17['date'].astype(str) + '01', format='%Y%m%d')\n",
        "Enq13['date'] = pd.to_datetime(Enq13['date'].astype(str) + '01', format='%Y%m%d')\n",
        "Enq20['date'] = pd.to_datetime(Enq20['date'].astype(str) + '01', format='%Y%m%d')\n",
        "Base_finale=pd.concat([Enq13,Enq17,Enq20])\n",
        "#Base_finale.to_excel('Base_finale.xlsx')\n"
      ],
      "metadata": {
        "id": "G4eayw9M8xD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ici certaines choses ont été raccourcis mais de fondamental n'a changé\n",
        "\n",
        "# I - premiere spécification\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from statsmodels.regression.linear_model import OLS\n",
        "import statsmodels.api as sm\n",
        "AA=Base_finale\n",
        "list(AA.columns)\n",
        "\n",
        "\n",
        "educ=pd.get_dummies(AA['_EDU_CAT'])\n",
        "age=pd.get_dummies(AA['_AGE_CAT'])\n",
        "income=pd.get_dummies(AA['_HH_INC_CAT'])\n",
        "numeracy=pd.get_dummies(AA['_NUM_CAT'])\n",
        "np.sum(educ['High School'])\n",
        "\n",
        "\n",
        "BC = pd.concat([AA, educ], axis=1).reindex(AA.index) #BC est pour Base complète. Ici, on complète la base avec des dummies\n",
        "BC = pd.concat([BC, age], axis=1).reindex(BC.index)\n",
        "BC = pd.concat([BC, income], axis=1).reindex(BC.index)\n",
        "BC = pd.concat([BC, numeracy], axis=1).reindex(BC.index)\n",
        "\n",
        "\"\"\"on code mtn pour le genre :\"\"\"\n",
        "\n",
        "gender=pd.get_dummies(AA['Q33'])\n",
        "gender.rename(columns={1: \"femme\"}, inplace=True)\n",
        "BC = pd.concat([BC, gender['femme']], axis=1).reindex(BC.index)\n",
        "\n",
        "\"\"\"c fait pour le genre.\n",
        "Faisons le ménage dans les non-réponses et dans les outliers\"\"\"\n",
        "\n",
        "BC=BC.dropna(subset=['Q8v2part2','Q9bv2part2']) #On supprime les personnes qui n'ont pas répondu aux questions sur les anticipations d'inflation.\n",
        "\"\"\"Supprimons les outliers\"\"\"\n",
        "\n",
        "test=BC[BC['Q8v2part2']<=20]\n",
        "test=test[test['Q8v2part2']>=-20]\n",
        "max(test['Q8v2part2'])\n",
        "\n",
        "BC.rename(columns={'Q8v2part2':'inflation anticipée'},inplace=True)\n",
        "\n",
        "model = OLS(BC['inflation anticipée'].astype('float'),BC['femme'].astype('float'))\n",
        "results = model.fit()\n",
        "su = results.summary()\n",
        "print(su)\n",
        "\n",
        "# Calcul de l'inflation :\n",
        "\n",
        "inflation_US = OECD[(OECD['Country'] == \"United States\") & (OECD['Subject2'] == \"Consumer prices: all items\")]\n",
        "inflation_US2 = pd.DataFrame({\n",
        "    'day': pd.to_datetime(inflation_US['Time'], format='%Y-%m-%d'),\n",
        "    'Inflation': inflation_US['Value'].astype(float)\n",
        "})\n",
        "\n",
        "inflation_US3 = pd.DataFrame({\n",
        "    'date': inflation_US2['day'],\n",
        "    'tx_evol_ann_pct': (inflation_US2['Inflation'] / inflation_US2['Inflation'].shift(12) - 1) * 100\n",
        "})\n",
        "test['inflation t']=0\n",
        "df3 = pd.merge(test,inflation_US3,how='outer',left_on=['date'],right_on=['date'])\n",
        "df3=df3[df3['Q1'].notnull()]\n",
        "BF=df3\n",
        "\n",
        "#DEFINITION D'un indicateur d'instabilité personnelle\n",
        "\n",
        "\"\"\"\n",
        "On va définir les variables qu'il serait pertinent d'inclure :\n",
        "\n",
        "Q3 : proba changement de résidence dans les douze prochain mois\n",
        "Q10 : 3 : chomeurs\n",
        "Q13new: proba de changer d'emploi\n",
        "Q25v2 : 3 : anticipe baisse de revenus\n",
        "Q30new : proba de ne pas réussir à payer un prêt\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "BF.loc[BF['Q25v2']==3, 'loss expectation'] = 1 #On binarise le fait d'anticiper une baisse de ses revenus\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Faisons quelques statistiques descriptives dessus :\n",
        "\"\"\"\n",
        "import statistics as stat\n",
        "\n",
        "def weighted_average(dataframe, value, weight):\n",
        "    val = dataframe[value]\n",
        "    wt = dataframe[weight]\n",
        "    return (val * wt).sum() / wt.sum()\n",
        "\n",
        "\n",
        "len(BF['Q8v2part2'])\n",
        "#\n",
        "\n",
        "BF.rename(columns={'tx_evol_ann_pct':'taux inflation','Q8v2part2':'inflation anticipée'},inplace=True)\n",
        "\n",
        "BF.dropna(subset=['weight'], inplace=True)\n",
        "poids = BF['weight'].astype('float')\n",
        "Y = BF['inflation anticipée'].astype('float')\n",
        "#\n",
        "\n",
        "\n",
        "#Alternative : on sépare les différents aspects de l'instabilité personnelle pour ne pas leur donner un poids arbitraire\n",
        "\n",
        "#Allure proba de changement de résidence sous 12 mois\n",
        "BF['Q3']\n",
        "print(\"nb de valeurs manquantes dans Q3 : \"+str(BF['Q3'].isnull().sum()))\n",
        "#440\n",
        "\n",
        "\n",
        "\n",
        "#Allure de l'indicatrice du chômage\n",
        "BF['Q10_3']\n",
        "print(\"nb de valeurs manquantes dans Q10_3 : \"+str(BF['Q10_3'].isnull().sum()))\n",
        "# nb de valeurs manquantes dans Q10_3 : 0\n",
        "# le chômage est tjrs renseigné, c'est cool\n",
        "\n",
        "\n",
        "\n",
        "#Allure proba changer d'emploi\n",
        "BF['Q13new']\n",
        "print(\"nb de valeurs manquantes dans Q13new : \"+str(BF['Q13new'].isnull().sum()))\n",
        "# nb de valeurs manquantes dans Q13new : 53054\n",
        "# c'est une catastrophe absolue, quasiment la moitié des participants n'y ont pas répondu... il faudra sans doute faire une régression qui ne le prend pas en compte\n",
        "\n",
        "\n",
        "\n",
        "#Allure anticipation baisse revenus\n",
        "BF['Q25v2']\n",
        "print(\"nb de valeurs manquantes dans Q25v2 : \"+str(BF['Q25v2'].isnull().sum()))\n",
        "# nb de valeurs manquantes dans Q25v2 : 60\n",
        "\n",
        "\n",
        "\n",
        "#Allure proba ne pas réussir à rembourser un prêt\n",
        "BF['Q30new']\n",
        "print(\"nb de valeurs manquantes dans Q30new : \"+str(BF['Q30new'].isnull().sum()))\n",
        "# nb de valeurs manquantes dans Q30new : 226\n",
        "\n",
        "\n",
        "\n",
        "BF\n"
      ],
      "metadata": {
        "id": "gSLY8goq8-aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ca je l'ai ravancé sinon ça bloqué\n",
        "\n",
        "#obtention d'une colonne proba diminution indices boursiers\n",
        "BF['Q6new_bis'] = 100-BF['Q6new']\n",
        "BF['Q6new_bis'] = BF['Q6new_bis'].astype(float)"
      ],
      "metadata": {
        "id": "RVRl7bgG9YC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C'est à partir de là que commence les modifications"
      ],
      "metadata": {
        "id": "m5qunh1l9pTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Tentative de maxi regression\n",
        "\n",
        "\n",
        "#On renomme les variables\n",
        "BF.rename(columns={'Q10_3':'chômage','Q3': 'proba chgt résidence','Q4new':'proba hausse chomage','Q5new':'proba hausse taux intêret','Q6new_bis':'proba diminution indices boursiers','Q25v2':'anticipation baisse revenus','Q30new':'proba non-remboursement prêt'},inplace=True)\n",
        "\n",
        "BF.rename(columns={'High': 'High_num','Over 60':'age > 60 ans','Under 40':'age < 40 ans','College':'Niveau licence','Over 100k':'revenus > $100k','Under 50k':'revenus < $50k'}, inplace=True)\n",
        "\n",
        "#On squarise les deux variables qui nous semblait chelou : hausse taux car ça paraissait être une relation quadratique || chgt residence (qui ne semblait pas avoir d'effet linéairement) pck on sait jamais\n",
        "BF['proba hausse taux intêret square'] = (BF['proba hausse taux intêret'] - 50)**2\n",
        "BF['proba chgt résidence square'] = (BF['proba chgt résidence']-50)**2\n",
        "\n",
        "\n",
        "#Fonction qui permet de créer les variables multipliées par l'inflation\n",
        "def produitisation(df,reg,a='taux inflation'):\n",
        "    for r in reg:\n",
        "        s = r + ' * inflation'\n",
        "        df[s]=df[a]*df[r]\n",
        "    return [r+' * inflation' for r in reg]\n",
        "\n",
        "#Crée les indicatrices temporelles\n",
        "def timisation(df,a=2013,b=2022):\n",
        "    for d in range(a,b+1):\n",
        "        df['t'+str(d)]=(df['date']>=str(d)+'-01-01')*1 - (df['date']>=str(d+1)+'-01-01')*1\n",
        "\n",
        "timisation(BF)\n",
        "\n",
        "\n",
        "#Ca c'est pour si on a besoin de la variable PIB que j'avais préparé\n",
        "\n",
        "#def PIBisation(df,a=2013,b=2022):\n",
        "#    v = float(pib.loc[str(a)])*df['t'+str(a)]\n",
        "#    for d in range(a+1,b+1):\n",
        "#        v = v + float(pib.loc[str(d)])*df['t'+str(d)]\n",
        "#    return v\n",
        "#\n",
        "#BF['PIB'] = PIBisation(BF)"
      ],
      "metadata": {
        "id": "dgTkidfr9kSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintenant que BF contient toutes les varibles qui nous intéresse, il ne nous reste plus qu'à sélectionner les variables sur lesquels on veut régresser à chaque fois : (_Prod est le vecteur contenant les varibles de _ multipliées par l'inflation)"
      ],
      "metadata": {
        "id": "j3IvYicl-vM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "Classicreg = ['taux inflation']\n",
        "Xreg = ['femme','age > 60 ans','age < 40 ans','Niveau licence','revenus > $100k','revenus < $50k','High_num']\n",
        "XregProd = produitisation(BF,Xreg)\n",
        "\n",
        "Times1reg = ['t'+str(y) for y in range(2013,2020)] #pour les regressions \"av\" : de 2013 à 2019\n",
        "Times2reg = ['t'+str(y) for y in range(2020,2023)] #pour les regressions \"ap\" : de été 2020 à 2022\n",
        "\n",
        "Macroreg = ['proba hausse chomage','proba hausse taux intêret','proba hausse taux intêret square','proba diminution indices boursiers']#des proba sur 100\n",
        "MacroregProd = produitisation(BF,Macroreg)\n",
        "\n",
        "# Microreg = ['chômage','anticipation baisse revenus','proba chgt résidence','proba chgt résidence square','proba non-remboursement prêt']#indicatrice et des proba sur 100\n",
        "Microreg = ['chômage','anticipation baisse revenus','proba non-remboursement prêt']#indicatrice et des proba sur 100\n",
        "MicroregProd = produitisation(BF,Microreg)\n",
        "\n",
        "\n",
        "#Toujours pour le PIB\n",
        "\n",
        "#Wreg = ['PIB']\n",
        "#WregProd = produitisation(BF,Wreg)\n"
      ],
      "metadata": {
        "id": "dJTuQskB-q5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Du coup après on choisit les regresseurs qu'on veut pour \"av\" (1) et \"ap\" (2) :"
      ],
      "metadata": {
        "id": "muH3qd8m_3ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regresseurs1 = Classicreg + Times1reg + Xreg +Microreg + Macroreg\n",
        "\n",
        "regresseurs2 = Classicreg + Times2reg + Xreg +  Microreg +  Macroreg"
      ],
      "metadata": {
        "id": "Uz0g2ISh_hu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regressions pour 2013-2019 :"
      ],
      "metadata": {
        "id": "-yLHCzx7AJJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#retrait des valeurs manquantes\n",
        "BF4 =BF.where(BF['date'].astype(str)<'2020-01-01').dropna(subset=regresseurs1+['inflation anticipée'])\n",
        "\n",
        "\n",
        "#du coup on re binarise Q25v2\n",
        "BF4['anticipation baisse revenus'] = (BF4['anticipation baisse revenus']==3)*1\n",
        "BF4['anticipation baisse revenus']=BF4.fillna(0)['anticipation baisse revenus']\n",
        "\n",
        "\n",
        "BF4.dropna(subset=['weight'], inplace=True)\n",
        "\n",
        "#transformation des colonnes en float\n",
        "for element in regresseurs1 :\n",
        "    BF4[element] = BF4[element].astype(float)\n",
        "\n",
        "poids = BF4['weight'].astype('float')\n",
        "\n",
        "\n",
        "Y1 = BF4['inflation anticipée'].astype(float)\n",
        "\n",
        "X1 = BF4[regresseurs1] \n",
        "\n",
        "X1 = sm.add_constant(X1)\n",
        "model1 = sm.WLS(Y1,X1, weights=poids)\n",
        "results1 = model1.fit()\n",
        "su1 = results1.summary()\n",
        "print(su1)"
      ],
      "metadata": {
        "id": "FhYNrefKAEHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regressions pour été 2020-2022 :"
      ],
      "metadata": {
        "id": "zt5HjWB9AQBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#retrait des valeurs manquantes\n",
        "BF5 =BF.where(BF['date'].astype(str)>'2020-06-20').dropna(subset=regresseurs2+['inflation anticipée'])\n",
        "\n",
        "\n",
        "#du coup on re binarise Q25v2\n",
        "BF5['anticipation baisse revenus'] = (BF5['anticipation baisse revenus']==3)*1\n",
        "BF5['anticipation baisse revenus']=BF5.fillna(0)['anticipation baisse revenus']\n",
        "\n",
        "\n",
        "BF5.dropna(subset=['weight'], inplace=True)\n",
        "\n",
        "#transformation des colonnes en float\n",
        "for element in regresseurs2 :\n",
        "    BF5[element] = BF5[element].astype(float)\n",
        "\n",
        "poids = BF5['weight'].astype('float')\n",
        "\n",
        "\n",
        "Y2 = BF5['inflation anticipée'].astype(float)\n",
        "X2 = BF5[regresseurs2]\n",
        "X2 = sm.add_constant(X2)\n",
        "model2 = sm.WLS(Y2,X2, weights=poids)\n",
        "results2 = model2.fit()\n",
        "su2 = results2.summary()\n",
        "print(su2)"
      ],
      "metadata": {
        "id": "f3h3G1utAE46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK du coup là on finit pour la première régression"
      ],
      "metadata": {
        "id": "S2EsEO7tAgDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deuxième spécification"
      ],
      "metadata": {
        "id": "2lElcGe1AjuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#J'ai pas touché à ça\n",
        "\n",
        "list(BF.head())\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "On doit définir les intervalles qui vont nous intéresser ici :\n",
        "\n",
        "pour l'inflation à court terme: Q9 inflation supérieur à 4% (bin 1, bin 2 et bin 3)\n",
        "\n",
        "déflation : bin6 à bin 10\n",
        "\n",
        "long terme: Q9c+les mêmes bin\n",
        "\n",
        "N.B : On considère pour la suite que les anticipations non remplies sont de 10 ( équiprobabilit de chaque tranche )\n",
        "\"\"\"\n",
        "\n",
        "BF['proba_st_high']=(BF['Q9_bin1'].fillna(10)+BF['Q9_bin2'].fillna(10)+BF['Q9_bin3'].fillna(10))\n",
        "\n",
        "BF['proba_st_defl']=(BF['Q9_bin6'].fillna(10)+BF['Q9_bin7'].fillna(10)+BF['Q9_bin8'].fillna(10)+BF['Q9_bin9'].fillna(10)+BF['Q9_bin10'].fillna(10))\n",
        "\n",
        "BF['proba_lt_high']=(BF['Q9c_bin1'].fillna(10)+BF['Q9c_bin2'].fillna(10)+BF['Q9c_bin3'].fillna(10))\n",
        "\n",
        "BF['proba_lt_defl']=(BF['Q9c_bin6'].fillna(10)+BF['Q9c_bin7'].fillna(10)+BF['Q9c_bin8'].fillna(10)+BF['Q9c_bin9'].fillna(10)+BF['Q9c_bin10'].fillna(10))"
      ],
      "metadata": {
        "id": "F0VpOVOfAfMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Du coup le choix des regresseurs :"
      ],
      "metadata": {
        "id": "wBDjW8R5AxhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Classicreg = ['taux inflation']\n",
        "Xreg = ['femme','age > 60 ans','age < 40 ans','Niveau licence','revenus > $100k','revenus < $50k','High_num']\n",
        "XregProd = produitisation(BF,Xreg)\n",
        "\n",
        "Timesreg = ['t'+str(y) for y in range(2013,2023)]\n",
        "\n",
        "\n",
        "Macroreg = ['proba hausse chomage','proba hausse taux intêret','proba hausse taux intêret square','proba diminution indices boursiers']#des proba sur 100\n",
        "MacroregProd = produitisation(BF,Macroreg)\n",
        "\n",
        "Microreg = ['chômage','anticipation baisse revenus','proba chgt résidence','proba chgt résidence square','proba non-remboursement prêt']#indicatrice et des proba sur 100\n",
        "MicroregPRod = produitisation(BF,Microreg)\n",
        "\n",
        "#Wreg = ['PIB']\n",
        "#WregProd = produitisation(BF,Wreg)"
      ],
      "metadata": {
        "id": "pQOB9XSbA1RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regresseurs1 = Classicreg + Times1reg + Xreg + XregProd +Macroreg\n",
        "\n",
        "\n",
        "regresseurs2 = Classicreg + Times2reg + Xreg +  XregProd +  Macroreg\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GVzZzPnbA7Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Du coup je pensais après choisir à chaque fois la proba qu'on voulait expliquée mais on peut tout faire en même temps si vous préférez"
      ],
      "metadata": {
        "id": "SpQR8QC-A-R8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regY = 'proba_st_high'\n",
        "# regY = 'proba_st_defl'\n",
        "# regY = 'proba_lt_high'\n",
        "# regY = 'proba_lt_defl'"
      ],
      "metadata": {
        "id": "WJP1cPhrA-k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Et rebelote !"
      ],
      "metadata": {
        "id": "EXwSLXjgBMqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#retrait des valeurs manquantes\n",
        "BF4 =BF.where(BF['date'].astype(str)<'2020-01-01').dropna(subset=regresseurs1+[regY])\n",
        "\n",
        "\n",
        "#du coup on re binarise Q25v2\n",
        "BF4['anticipation baisse revenus'] = (BF4['anticipation baisse revenus']==3)*1\n",
        "BF4['anticipation baisse revenus']=BF4.fillna(0)['anticipation baisse revenus']\n",
        "\n",
        "\n",
        "BF4.dropna(subset=['weight'], inplace=True)\n",
        "\n",
        "#transformation des colonnes en float\n",
        "for element in regresseurs1 :\n",
        "    BF4[element] = BF4[element].astype(float)\n",
        "\n",
        "poids = BF4['weight'].astype('float')\n",
        "\n",
        "\n",
        "Y1 = BF4[regY].astype(float)\n",
        "X1 = BF4[regresseurs1] #sur la periode 2013-2019 : [:97043]\n",
        "X1 = sm.add_constant(X1)\n",
        "model1 = sm.WLS(Y1,X1, weights=poids)\n",
        "results1 = model1.fit()\n",
        "su1 = results1.summary()\n",
        "print(su1)\n",
        "\n"
      ],
      "metadata": {
        "id": "qVUfCCuLBOr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#retrait des valeurs manquantes\n",
        "BF5 =BF.where(BF['date'].astype(str)>'2020-06-20').dropna(subset=regresseurs2+[regY])\n",
        "\n",
        "\n",
        "#du coup on re binarise Q25v2\n",
        "BF5['anticipation baisse revenus'] = (BF5['anticipation baisse revenus']==3)*1\n",
        "BF5['anticipation baisse revenus']=BF5.fillna(0)['anticipation baisse revenus']\n",
        "\n",
        "\n",
        "BF5.dropna(subset=['weight'], inplace=True)\n",
        "\n",
        "#transformation des colonnes en float\n",
        "for element in regresseurs2 :\n",
        "    BF5[element] = BF5[element].astype(float)\n",
        "\n",
        "poids = BF5['weight'].astype('float')\n",
        "\n",
        "Y2 = BF5[regY].astype(float)\n",
        "X2 = BF5[regresseurs2]#.where(BF4['date']>'2020-06-20').dropna(subset=regresseurs) #sur la periode été 2020 - 2022 : [103944:]\n",
        "X2 = sm.add_constant(X2)\n",
        "model2 = sm.WLS(Y2,X2, weights=poids)\n",
        "results2 = model2.fit()\n",
        "su2 = results2.summary()\n",
        "print(su2)\n"
      ],
      "metadata": {
        "id": "MD6-hd2BBWHa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}